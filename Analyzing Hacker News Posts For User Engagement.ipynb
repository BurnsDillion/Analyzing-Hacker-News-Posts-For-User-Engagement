{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Hacker News Posts For User Engagement\n",
    "\n",
    "`Hacker News` is a site started by the startup incubator `Y Combinator`, where users can submit posts and be voted and commented upon. This website is similar to Reddit, but has a philosophy of only posting 'interesting' topics. The website says if it's likely to be on the news, then it shoud not be on the site. \n",
    "\n",
    "The data set was over 300,000 thousand rows but was shortened to 20,000 by removing posts not commented on as well as random sampling the rest. \n",
    "\n",
    "Below are the columns:\n",
    "\n",
    " |Name| Description|\n",
    " |---|---|\n",
    " |`title`| title of the post (self explanatory)|\n",
    " |`url`| the url of the item being linked to|\n",
    " |`num_points`| the number of upvotes the post received|\n",
    " |`num_comments`| the number of comments the post received|\n",
    " |`author`| the name of the account that made the post|\n",
    " |`created_at`| the date and time the post was made (the time zone is Eastern Time in the US)|\n",
    "\n",
    "Currently, I am only interested in posts that begin with:\n",
    "- `Ask HN`\n",
    "- `Show HN`\n",
    "\n",
    "On this website, users can post on either Ask HN or Show HN depending on the type of post.\n",
    "\n",
    "My goal is to find which posts recieve the most amount of user to user interaction (comments), and what time of day is best to post to receive that user to user interaction.\n",
    "\n",
    "# Introduction\n",
    "\n",
    "I will begin by opening the file, reading it in, then creating a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'],\n",
       " ['12224879',\n",
       "  'Interactive Dynamic Video',\n",
       "  'http://www.interactivedynamicvideo.com/',\n",
       "  '386',\n",
       "  '52',\n",
       "  'ne0phyte',\n",
       "  '8/4/2016 11:52'],\n",
       " ['10975351',\n",
       "  'How to Use Open Source and Shut the Fuck Up at the Same Time',\n",
       "  'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/',\n",
       "  '39',\n",
       "  '10',\n",
       "  'josep2',\n",
       "  '1/26/2016 19:30'],\n",
       " ['11964716',\n",
       "  \"Florida DJs May Face Felony for April Fools' Water Joke\",\n",
       "  'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/',\n",
       "  '2',\n",
       "  '1',\n",
       "  'vezycash',\n",
       "  '6/23/2016 22:20'],\n",
       " ['11919867',\n",
       "  'Technology ventures: From Idea to Enterprise',\n",
       "  'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',\n",
       "  '3',\n",
       "  '1',\n",
       "  'hswarna',\n",
       "  '6/17/2016 0:01']]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Opening, reading, and listing the file\n",
    "\n",
    "from csv import reader\n",
    "import csv\n",
    "\n",
    "open_file = open('hacker_news.csv', encoding='utf8')\n",
    "read_file = reader(open_file)\n",
    "hn = list(read_file)\n",
    "\n",
    "# Displaying the first five rows\n",
    "\n",
    "hn[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing the Header\n",
    "\n",
    "Above, it will show the headers for the data set. Do analyze this date I will need to separate the header from the rest of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "headers = hn[0]\n",
    "h_news = hn[1:]\n",
    "\n",
    "print(headers)\n",
    "print('\\n')\n",
    "print(h_news[:5])      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HN Post Types\n",
    "\n",
    "Because I only care for `Ask HN` and `Show HN`, I will separate these types of posts into lists. I will have three lists:\n",
    "\n",
    "- Ask posts\n",
    "- Show posts\n",
    "- Other posts\n",
    "\n",
    "I will look through the `h_news` list (list without the header) and separate the data into the lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'] \n",
      "\n",
      "1744\n",
      "['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55'] \n",
      "\n",
      "1162\n",
      "['10627194', 'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform', 'https://iot.seeed.cc', '26', '22', 'kfihihc', '11/25/2015 14:03'] \n",
      "\n",
      "17194\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# New lists to sort the data into post types\n",
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in h_news:\n",
    "    # Pulling out the title row, which is index 2\n",
    "    title = row[1]\n",
    "    \n",
    "    # Sorting the rows into particular lists based off the title\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "\n",
    "# Printing the header and each column with the amount of each post\n",
    "print(headers, '\\n')\n",
    "print(len(ask_posts))\n",
    "print(ask_posts[0], '\\n')\n",
    "print(len(show_posts))\n",
    "print(show_posts[0], '\\n')\n",
    "print(len(other_posts))\n",
    "print(other_posts[0], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments\n",
    "\n",
    "Now I will look to see which type of post, `Ask HN` or `Show HN`, had more comments on average.\n",
    "\n",
    "To do this I will do the following:\n",
    "\n",
    "- Create variables for each type of post\n",
    "- Iterate through each post list and add the number of comments to each post to the respective variable\n",
    "- Get the average number of posts by dividing by the number of posts in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of 'Ask HN' posts are: 14.038417431192661 \n",
      "\n",
      "The average number of 'Show HN' posts are: 10.31669535283993 \n",
      "\n",
      "The average number of 'Other' posts are: 26.8730371059672 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count Variables for the types of posts\n",
    "total_ask_comments = 0\n",
    "total_show_comments = 0\n",
    "total_other_comments = 0\n",
    "\n",
    "# Each type of post will be iterated and the average will be found\n",
    "for row in ask_posts:\n",
    "    # Pulling out the comment column with index 4\n",
    "    comments = int(row[4])\n",
    "    total_ask_comments += comments\n",
    "    \n",
    "avg_ask_comments = total_ask_comments / 1744\n",
    "\n",
    "for row in show_posts:\n",
    "    comments = int(row[4])\n",
    "    total_show_comments += comments\n",
    "\n",
    "avg_show_comments = total_show_comments / 1162\n",
    "\n",
    "for row in other_posts:\n",
    "    comments = int(row[4])\n",
    "    total_other_comments += comments \n",
    "    \n",
    "avg_other_comments = total_other_comments / 17194\n",
    "\n",
    "# Each post's average will be displayed with a newline imputed after\n",
    "print(\"The average number of 'Ask HN' posts are:\", avg_ask_comments, '\\n')\n",
    "print(\"The average number of 'Show HN' posts are:\", avg_show_comments, '\\n')\n",
    "print(\"The average number of 'Other' posts are:\", avg_other_comments, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: Currently, this analysis is only based off of the `Ask HN` and `Show HN` posts. The 'Other' posts will be ignored for now.**\n",
    "\n",
    "As you can see above, `Ask HN` posts on average received about 4 more comments per post than `Show HN`. This could be because it is the nature of the post. If a user asks a question they are probably more likely to recieve an answer than a user who is just showing something.\n",
    "\n",
    "Since `Ask HN` posts on average recieve more posts, we will focus the rest of our analysis on `Ask HN` posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n"
     ]
    }
   ],
   "source": [
    "# Displaying the headers to prevent having to scroll up to view them\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the number of ask posts and comments by hour\n",
    "\n",
    "I will now calculate the number of `Ask HN` posts and comments by the hour. \n",
    "\n",
    "To do this I will have to do the following:\n",
    "- Import the `datetime` module to help parse through the dates and times\n",
    "- Pull the `Created_at` and `num_comments` columns you see above at index `-1` and `4` into a list of lists\n",
    "- Create a frequency table for display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comments By Hour:\n",
      "{'09': 251, '13': 1253, '10': 793, '14': 1416, '16': 1814, '23': 543, '12': 687, '17': 1146, '15': 4477, '21': 1745, '20': 1722, '02': 1381, '18': 1439, '03': 421, '05': 464, '19': 1188, '01': 683, '22': 479, '08': 492, '04': 337, '00': 447, '06': 397, '07': 267, '11': 641} \n",
      "\n",
      "Posts By Hour:\n",
      "{'09': 45, '13': 85, '10': 59, '14': 107, '16': 108, '23': 68, '12': 73, '17': 100, '15': 116, '21': 109, '20': 80, '02': 58, '18': 109, '03': 54, '05': 46, '19': 110, '01': 60, '22': 71, '08': 48, '04': 47, '00': 55, '06': 44, '07': 34, '11': 58}\n"
     ]
    }
   ],
   "source": [
    "# Importing the datetime module as dt\n",
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "# There will be two elements to this loop: Time created and Comments\n",
    "for row in ask_posts:\n",
    "    created = row[-1]\n",
    "    comments = int(row[4])\n",
    "    \n",
    "    # Each element will be appended to the result_list together, created a list of lists\n",
    "    result_list.append([created, comments])\n",
    "    \n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "# This variable is to tell the strptime method what format the date from the dataset is in\n",
    "date_format = \"%m/%d/%Y %H:%M\"\n",
    "\n",
    "for row in result_list:\n",
    "    created = row[0]\n",
    "    comments = int(row[1])\n",
    "    \n",
    "    # Creating a datetime object that allows me to pull just the hour from the date\n",
    "    hour = dt.datetime.strptime(created, date_format).strftime(\"%H\")\n",
    "    \n",
    "    \n",
    "    # If the hour is not already in the dictionary, then it will create it,\n",
    "    # otherwise is will increment the comment number by the number of comments and the hour number by 1\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = comments\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += comments\n",
    "        \n",
    "        \n",
    "print(\"Comments By Hour:\")        \n",
    "print(comments_by_hour, '\\n')\n",
    "print(\"Posts By Hour:\")\n",
    "print(counts_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average number of comments per hour\n",
    "\n",
    "\n",
    "I will now create a list of lists where the first element is the hour and the second element is the average number of comments per post\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['09', 5.5777777777777775],\n",
       " ['13', 14.741176470588234],\n",
       " ['10', 13.440677966101696],\n",
       " ['14', 13.233644859813085],\n",
       " ['16', 16.796296296296298],\n",
       " ['23', 7.985294117647059],\n",
       " ['12', 9.41095890410959],\n",
       " ['17', 11.46],\n",
       " ['15', 38.5948275862069],\n",
       " ['21', 16.009174311926607],\n",
       " ['20', 21.525],\n",
       " ['02', 23.810344827586206],\n",
       " ['18', 13.20183486238532],\n",
       " ['03', 7.796296296296297],\n",
       " ['05', 10.08695652173913],\n",
       " ['19', 10.8],\n",
       " ['01', 11.383333333333333],\n",
       " ['22', 6.746478873239437],\n",
       " ['08', 10.25],\n",
       " ['04', 7.170212765957447],\n",
       " ['00', 8.127272727272727],\n",
       " ['06', 9.022727272727273],\n",
       " ['07', 7.852941176470588],\n",
       " ['11', 11.051724137931034]]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New list for average comments by hour\n",
    "avg_by_hour = []\n",
    "\n",
    "for row in comments_by_hour:\n",
    "        \n",
    "        # Selecting an hour, dividing the number of comments in that hour\n",
    "        # by the number of posts in that hour to find the average. Then the\n",
    "        # results are appended to the avg_by_hour list.\n",
    "        avg_by_hour.append([row, comments_by_hour[row] / counts_by_hour[row]])\n",
    "        \n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting the values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.5777777777777775, '09'],\n",
       " [14.741176470588234, '13'],\n",
       " [13.440677966101696, '10'],\n",
       " [13.233644859813085, '14'],\n",
       " [16.796296296296298, '16'],\n",
       " [7.985294117647059, '23'],\n",
       " [9.41095890410959, '12'],\n",
       " [11.46, '17'],\n",
       " [38.5948275862069, '15'],\n",
       " [16.009174311926607, '21'],\n",
       " [21.525, '20'],\n",
       " [23.810344827586206, '02'],\n",
       " [13.20183486238532, '18'],\n",
       " [7.796296296296297, '03'],\n",
       " [10.08695652173913, '05'],\n",
       " [10.8, '19'],\n",
       " [11.383333333333333, '01'],\n",
       " [6.746478873239437, '22'],\n",
       " [10.25, '08'],\n",
       " [7.170212765957447, '04'],\n",
       " [8.127272727272727, '00'],\n",
       " [9.022727272727273, '06'],\n",
       " [7.852941176470588, '07'],\n",
       " [11.051724137931034, '11']]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Swapping the avg by hour to sort by the average\n",
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "\n",
    "swap_avg_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[38.5948275862069, '15'],\n",
       " [23.810344827586206, '02'],\n",
       " [21.525, '20'],\n",
       " [16.796296296296298, '16'],\n",
       " [16.009174311926607, '21'],\n",
       " [14.741176470588234, '13'],\n",
       " [13.440677966101696, '10'],\n",
       " [13.233644859813085, '14'],\n",
       " [13.20183486238532, '18'],\n",
       " [11.46, '17'],\n",
       " [11.383333333333333, '01'],\n",
       " [11.051724137931034, '11'],\n",
       " [10.8, '19'],\n",
       " [10.25, '08'],\n",
       " [10.08695652173913, '05'],\n",
       " [9.41095890410959, '12'],\n",
       " [9.022727272727273, '06'],\n",
       " [8.127272727272727, '00'],\n",
       " [7.985294117647059, '23'],\n",
       " [7.852941176470588, '07'],\n",
       " [7.796296296296297, '03'],\n",
       " [7.170212765957447, '04'],\n",
       " [6.746478873239437, '22'],\n",
       " [5.5777777777777775, '09']]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorting the columns from highest to lowest\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "\n",
    "sorted_swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for `Ask HN` Comments:\n",
      "15:00:38.59 average comments per post\n",
      "02:00:23.81 average comments per post\n",
      "20:00:21.52 average comments per post\n",
      "16:00:16.80 average comments per post\n",
      "21:00:16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "# Printing the top 5 hours for Ask Posts\n",
    "\n",
    "print(\"Top 5 Hours for `Ask HN` Comments:\")\n",
    "for avg, hr in sorted_swap[:5]:\n",
    "    print(\n",
    "        \"{}:{:.2f} average comments per post\".format(dt.datetime.strptime(hr, \"%H\").strftime(\"%H:%M\"), avg\n",
    "          )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "From above, the Top 5 hours to post are listed. The best time to post is by far 3 PM (Eastern Time) with an average 38.59 comments *per* post. If a user is looking for the highest amount of user to user engagement as possible, then posting at this time will be ideal which would be 10 AM my time (Hawaii Standard Time). This data covers 12 months from 2016, so times could be very different by now, but this is still a great place to start. \n",
    "\n",
    "Another idea for further analysis would be to find the top ten authors who receive the most comments and look into what kind of posts do they post. That way you could possibly find the following information:\n",
    "\n",
    "- How do the top authors write their titles?\n",
    "- What type of posts are the top authors posting?\n",
    "- What is the format of the post that the top authors using? Are they the same? Are they different?\n",
    "\n",
    "You can use this new information to increase the value of your own posts. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
